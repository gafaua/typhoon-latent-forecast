{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook contains various code snippets for exploration of the Digital Typhoon Dataset and for exploration of the latent space built using a MoCo trained vision encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyphoon2.DigitalTyphoonDataset import DigitalTyphoonDataset as DTD\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from lib.utils.fisheye import FishEye\n",
    "\n",
    "transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    #T.Resize(256),\n",
    "    FishEye(256, .5),\n",
    "    #T.RandomApply([T.GaussianBlur(3, [.1, 2.])], p=0.5),\n",
    "    #T.RandomSolarize(0.6, p=0),\n",
    "    #T.RandomHorizontalFlip(p=0.5),\n",
    "    #T.RandomVerticalFlip(p=0.5),\n",
    "    #T.Normalize(mean=269.15, std=24.14),\n",
    "])\n",
    "\n",
    "def transform_func(obj):\n",
    "    img, labels = obj\n",
    "    img_range = [150, 350]\n",
    "    img, labels = obj\n",
    "    img = (img - img_range[0])/(img_range[1]-img_range[0])\n",
    "\n",
    "    return transforms(img.astype(np.float32)), labels\n",
    "\n",
    "prefix=\"/fs9/datasets/typhoon-202404/wnp\"\n",
    "\n",
    "dataset = DTD(f\"{prefix}/image/\",\n",
    "              f\"{prefix}/metadata/\",\n",
    "              f\"{prefix}/metadata.json\",\n",
    "              get_images_by_sequence=False,\n",
    "              labels=(\"pressure\", \"wind\", \"lat\", \"lng\", \"grade\", \"interpolated\", \"mask_1_percent\"),\n",
    "              split_dataset_by=\"sequence\",\n",
    "              load_data_into_memory=\"track\",\n",
    "              filter_func= lambda x: (x.year() == 2017 or x.year() == 2018) and x.grade() < 6,\n",
    "              transform=None,#transform_func,\n",
    "              ignore_list=[],\n",
    "              verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9582\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(dataset.number_of_nonempty_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192956/192956 [00:02<00:00, 79475.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pressure| mean: 983.7059485063952 std: 22.575873184072947\n",
      "Wind| mean: 36.85347954974191 std: 32.76338099425619\n",
      "Lat| mean: 22.584546062314725 std: 10.60326799814119\n",
      "Lng| mean: 136.20306411824458 std: 17.278662751998144\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pressures = []\n",
    "winds = []\n",
    "lat = []\n",
    "lng = []\n",
    "grades = []\n",
    "interpolateds = []\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    _, labels = dataset[i]\n",
    "    pressures.append(labels[0])\n",
    "    winds.append(labels[1])\n",
    "    lat.append(labels[2])\n",
    "    lng.append(labels[3])\n",
    "    grades.append(labels[4])\n",
    "    interpolateds.append(labels[6])\n",
    "print(f\"Pressure| mean: {np.mean(pressures)} std: {np.std(pressures)}\")\n",
    "print(f\"Wind| mean: {np.mean(winds)} std: {np.std(winds)}\")\n",
    "print(f\"Lat| mean: {np.mean(lat)} std: {np.std(lat)}\")\n",
    "print(f\"Lng| mean: {np.mean(lng)} std: {np.std(lng)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-40486886.0\n",
      "40679842.0\n"
     ]
    }
   ],
   "source": [
    "ss = sum(interpolateds)\n",
    "print(len(dataset) - ss)\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2061"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) - np.sum(np.array(interpolateds)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(pressures, bins=20,)\n",
    "plt.xlabel(\"Central pressure (hPa)\")\n",
    "plt.title(\"Distribution of central pressures (hPa) through Digital Typhoon Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "plt.scatter(x=winds, y=grades)\n",
    "plt.xlabel(\"10 min sustained wind speed (kt)\")\n",
    "plt.ylabel(\"Grade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22029\n"
     ]
    }
   ],
   "source": [
    "from pyphoon2.DigitalTyphoonDataset import DigitalTyphoonDataset as DTD\n",
    "\n",
    "dataset = DTD(image_dir=\"/fs9/gaspar/data/WP/image/\",\n",
    "              metadata_dir=\"/fs9/gaspar/data/WP/metadata/\",\n",
    "              metadata_json=\"/fs9/gaspar/data/WP/metadata.json\",\n",
    "              get_images_by_sequence=False,\n",
    "              labels=(\"pressure\", \"wind\", \"lat\", \"lng\", \"grade\"),\n",
    "              split_dataset_by=\"sequence\",\n",
    "              load_data_into_memory=\"track\",\n",
    "              filter_func= lambda x: x.grade() == 6,\n",
    "              transform=None,#transform_func,\n",
    "              ignore_list=[],\n",
    "              verbose=False)\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sequences: 1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1099/1099 [00:01<00:00, 657.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences with transition in grade: 1097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"All sequences: {len(dataset)}\")\n",
    "transitions = []\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    _, labels = dataset[i]\n",
    "    grades = np.unique(labels[:,-1])\n",
    "    if len(grades) > 1:\n",
    "        transitions.append(grades)\n",
    "print(f\"Sequences with transition in grade: {len(transitions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_trans = []\n",
    "for t in transitions:\n",
    "    if 6 in t:\n",
    "        et_trans.append(t)\n",
    "print(len(et_trans))\n",
    "print(et_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "img, label = dataset[15175]\n",
    "#print(torch.median(img))\n",
    "plt.title(label)\n",
    "plt.imshow(img.squeeze(), cmap=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def get_of_fisheye(height, width, center, magnitude):\n",
    "  xx, yy = torch.linspace(-1, 1, width), torch.linspace(-1, 1, height)\n",
    "  gridy, gridx  = torch.meshgrid(yy, xx)   #create identity grid\n",
    "  grid = torch.stack([gridx, gridy], dim=-1)\n",
    "  #print(grid)\n",
    "  d =  center - grid         #calculate the distance(cx - x, cy - y)\n",
    "  d_sum = torch.sqrt((d**2).sum(axis=-1)) # sqrt((cx-x)**2 + (cy-y)**2)\n",
    "  #grid = grid.clamp(0,1)\n",
    "  grid += d * d_sum.unsqueeze(-1) * magnitude #calculate dx & dy and add to original values\n",
    "  return grid.unsqueeze(0)    #unsqueeze(0) since the grid needs to be 4D.\n",
    "\n",
    "def fisheye_grid(width, height, cx, cy, k):\n",
    "    x = torch.linspace(-1, 1, width)\n",
    "    y = torch.linspace(-1, 1, height)\n",
    "    xx, yy = torch.meshgrid(x, y)\n",
    "\n",
    "    # Convert to polar coordinates\n",
    "    r = torch.sqrt(xx**2 + yy**2)\n",
    "\n",
    "    theta = torch.atan2(yy,xx)\n",
    "\n",
    "    # Apply fisheye distortion equation\n",
    "    r = r**k\n",
    "\n",
    "    # Convert back to cartesian coordinates\n",
    "    new_x = cx + r * torch.sin(theta)\n",
    "    new_y = cy + r * torch.cos(theta)\n",
    "\n",
    "    # Stack the coordinates\n",
    "    grid = torch.stack([new_x, new_y], dim=-1)\n",
    "    grid = torch.clamp(grid, -1, 1)\n",
    "\n",
    "    return grid\n",
    "\n",
    "def fisheye(image, cx, cy, k):\n",
    "    # get image size\n",
    "    height, width = image.shape[-2:]\n",
    "\n",
    "    # generate fisheye grid\n",
    "    grid = fisheye_grid(int(width/2), int(height/2), cx, cy, k)\n",
    "    grid = grid.unsqueeze(0).to(image.device).float()\n",
    "\n",
    "    # apply grid sample\n",
    "    warped_image = F.grid_sample(image.unsqueeze(0), grid,align_corners=True)\n",
    "    #cropped_image = tv.center_crop(warped_image, height)\n",
    "    return warped_image.squeeze(0)\n",
    "\n",
    "def fisheye_transform(img, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Applies a fisheye transformation to the input image.\n",
    "    \n",
    "    Args:\n",
    "        img (torch.Tensor): Input image tensor of shape (B, C, H, W).\n",
    "        alpha (float): Fisheye transformation parameter (0 < alpha < 1).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Transformed image tensor of shape (B, C, H, W).\n",
    "    \"\"\"\n",
    "    B, C, H, W = img.shape\n",
    "\n",
    "    # Create a grid of normalized coordinates\n",
    "    x, y = torch.meshgrid(torch.linspace(-1, 1, int(W/2)), torch.linspace(-1, 1, int(H/2)))\n",
    "    coords = torch.stack((y, x), dim=-1).to(img.device)\n",
    "\n",
    "    # Apply fisheye transformation to the coordinates\n",
    "    r = torch.sqrt(coords[:, :, 0]**2 + coords[:, :, 1]**2)\n",
    "    radial_scale = torch.pow(r, alpha)#(1 - torch.pow(r, alpha)) / r\n",
    "    radial_scale[r == 0] = 1.0\n",
    "    fisheye_coords = coords * torch.unsqueeze(radial_scale, -1)\n",
    "\n",
    "    # Clamp the transformed coordinates to [-1, 1] range\n",
    "    fisheye_coords = torch.clamp(fisheye_coords, min=-1, max=1)\n",
    "\n",
    "    # Sample the input image using the transformed coordinates\n",
    "    fisheye_img = F.grid_sample(img, fisheye_coords.unsqueeze(0).repeat(B, 1, 1, 1), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "    return fisheye_img\n",
    "#fisheye_grid = get_of_fisheye(256, 256, torch.tensor([0,0]),5)\n",
    "#fisheye_grid = fisheye_grid(256, 256, 128,128, 1.5)\n",
    "\n",
    "#fisheye_output = F.grid_sample(img.unsqueeze(0), fisheye_grid)\n",
    "#fisheye_output = fisheye(img, 0, 0, 1.2)\n",
    "fisheye_output = fisheye_transform(img.unsqueeze(0), alpha=0.5)\n",
    "plt.title(label)\n",
    "plt.imshow(fisheye_output.squeeze(), cmap=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "images, labels = dataset[789]\n",
    "s = len(labels)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "spl = 220#np.random.randint(s)\n",
    "axs[0].set_title(str(labels[spl]) + f\" {spl}/{s}\")\n",
    "axs[0].imshow(images[spl], cmap=\"grey\")\n",
    "spl = np.min((s-1, spl+np.random.randint(1,4)))\n",
    "axs[1].set_title(str(labels[spl]) + f\" {spl}/{s}\")\n",
    "axs[1].imshow(images[spl], cmap=\"grey\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from lib.utils.dataset import SequenceTyphoonDataset as STD\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "dataset = STD(labels=[\"month\", \"day\", \"hour\", \"pressure\", \"wind\", \"grade\"],\n",
    "              include_images=False,\n",
    "              x=[0,1,2,3,4,5],\n",
    "              y=[3,4,5],\n",
    "              num_inputs=12,\n",
    "              num_preds=1)\n",
    "train, val, test = dataset.random_split([0.7, 0.15, 0.15], split_by=\"sequence\")\n",
    "\n",
    "print(f\"\\n{len(train)} train sequences\")\n",
    "print(f\"{len(val)} val sequences\")\n",
    "print(f\"{len(test)} test sequences\")\n",
    "\n",
    "test_loader = DataLoader(test,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 74])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp, preds = dataset[569]\n",
    "inp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expected model inputs: 6\n",
      "Expected model outputs: 6\n",
      "\n",
      "[782, 167, 167] 1116\n",
      "1116\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from lib.utils.dataset import SequenceTyphoonDataset as STD\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "dataset = STD(labels=[\"grade\"],\n",
    "              preprocessed_path=\"vitp_10k_w6\",\n",
    "              latent_dim=384,\n",
    "              x=[0],\n",
    "              y=[0],\n",
    "              num_inputs=1,\n",
    "              num_preds=1,\n",
    "              interval=1,\n",
    "              #filter_func= lambda x: x.grade() < 6,\n",
    "              output_all=True,\n",
    "              prefix = \"/fs9/datasets/typhoon-202404/wnp\")\n",
    "#dataset = dataset.random_split([1], split_by=\"sequence\")[0]\n",
    "train, val, test = dataset.random_split([0.7, 0.15, 0.15], split_by=\"sequence\")\n",
    "\n",
    "train_loader = DataLoader(train,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/167 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [00:00<00:00, 180.43it/s]\n",
      "100%|██████████| 782/782 [00:03<00:00, 223.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28498, 384])\n",
      "torch.Size([134188, 384])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_grades = []\n",
    "train_pressures = []\n",
    "train_features = []\n",
    "train_seq_ids = []\n",
    "train_pic_ids = []\n",
    "\n",
    "test_grades = []\n",
    "test_pressures = []\n",
    "test_features = []\n",
    "test_seq_ids = []\n",
    "test_pic_ids = []\n",
    "\n",
    "num_features = 512\n",
    "\n",
    "for i, (features, seq_id) in enumerate(tqdm(test_loader)):\n",
    "    features = features.squeeze()\n",
    "    test_grades.append(features[:,dataset.x])\n",
    "    #test_pressures.append(features[:,dataset.y])\n",
    "    test_features.append(features[:,-num_features:])\n",
    "    test_seq_ids.extend([i]*len(features))\n",
    "    test_pic_ids.extend(list(range(len(features))))\n",
    "\n",
    "test_grades = torch.argmax(torch.concatenate(test_grades), dim=1) + 2\n",
    "#test_pressures = torch.concatenate(test_pressures)\n",
    "test_features = torch.concatenate(test_features)\n",
    "\n",
    "for i, (features, seq_id)  in enumerate(tqdm(train_loader)):\n",
    "    features = features.squeeze()\n",
    "    train_grades.append(features[:,dataset.x])\n",
    "    #train_pressures.append(features[:,dataset.y])\n",
    "    train_features.append(features[:,-num_features:])\n",
    "    train_seq_ids.extend([i]*len(features))\n",
    "    train_pic_ids.extend(list(range(len(features))))\n",
    "\n",
    "train_grades = torch.argmax(torch.concatenate(train_grades), dim=1) + 2\n",
    "#train_pressures = torch.concatenate(train_pressures)\n",
    "train_features = torch.concatenate(train_features)\n",
    "\n",
    "print(test_features.shape)\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "max_clusters = 10\n",
    "Ks = range(2, max_clusters)\n",
    "km = [KMeans(n_clusters=i) for i in Ks]\n",
    "scores = []\n",
    "\n",
    "for kmeans in tqdm(km):\n",
    "    kmeans.fit(train_features)\n",
    "    scores.append(kmeans.inertia_)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.plot(Ks, scores)\n",
    "plt.grid(True)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Elbow curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=10)\n",
    "train_clusters = km.fit_predict(train_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_seq = train_seq_ids[0]\n",
    "curr_img = train_clusters[0]\n",
    "\n",
    "seq_transitions = dict()\n",
    "seq_transitions[train_seq_ids[0]] = []\n",
    "\n",
    "all_sequences = [[train_clusters[0]]]\n",
    "all_transitions = []\n",
    "\n",
    "for i in tqdm(range(1, len(train_clusters))):\n",
    "    if curr_seq == train_seq_ids[i]:\n",
    "        all_transitions.append((curr_img, train_clusters[i]))\n",
    "        seq_transitions[train_seq_ids[i]].append((curr_img, train_clusters[i]))\n",
    "        all_sequences[-1].append(train_clusters[i])\n",
    "    else:\n",
    "        curr_seq = train_seq_ids[i]\n",
    "        seq_transitions[train_seq_ids[i]] = []\n",
    "        all_sequences.append([train_clusters[i]])\n",
    "\n",
    "    curr_img = train_clusters[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_dict = dict()\n",
    "\n",
    "for t in all_transitions:\n",
    "    if t in transition_dict:\n",
    "        transition_dict[t] += 1\n",
    "    else:\n",
    "        transition_dict[t] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(transition_dict))\n",
    "\n",
    "print(sorted([(k,v) for k,v in transition_dict.items()], key=lambda x: x[1], reverse=True))\n",
    "\n",
    "filtered_transitions = [t for t in all_transitions if t[0]!=t[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "G.add_nodes_from(range(10))\n",
    "G.add_edges_from(filtered_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = nx.kamada_kawai_layout(G)\n",
    "\n",
    "nx.draw_networkx(G, pos=position, arrows=True, node_size=50, font_size=5, width=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaspar/env/typhoon/lib/python3.9/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "\n",
    "# TSNE(2).fit_transform(all_features)\n",
    "umap_ = umap.UMAP(n_components=2)\n",
    "umap_results = umap_.fit_transform(train_features)\n",
    "umap_results_test = umap_.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7416075237611591\n",
      "[0.66488367 0.07672385]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(2)\n",
    "pca_results = pca.fit_transform(train_features)\n",
    "print(sum(pca.explained_variance_ratio_))\n",
    "print(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umap visualization of the train data, projected to the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "df = pd.DataFrame()\n",
    "show_test = False\n",
    "\n",
    "df[\"x\"]=umap_results_test[:, 0] if show_test else umap_results[:, 0]\n",
    "df[\"y\"]=umap_results_test[:, 1] if show_test else umap_results[:, 1]\n",
    "df[\"seq_ids\"]=test_seq_ids if show_test else train_seq_ids\n",
    "df[\"pic_ids\"]=test_pic_ids if show_test else train_pic_ids\n",
    "df[\"grades\"]=test_grades if show_test else train_grades\n",
    "\n",
    "hovertemplate= \"\"\"\n",
    "<b>Grade</b>: %{customdata[0]}<br>\n",
    "<b>Seq ID </b>: %{customdata[1]}<br>\n",
    "<b>Pic ID </b>: %{customdata[2]}<br>\n",
    "<b>X</b>: %{x:,.2f}\n",
    "<b>Y</b>: %{y:,.2f}\n",
    "<extra></extra>\n",
    "\"\"\"\n",
    "customdata=np.stack((df[\"grades\"], df[\"seq_ids\"], df[\"pic_ids\"]), axis=-1)\n",
    "fig=px.scatter(df,\n",
    "           x=\"x\",\n",
    "           y=\"y\",\n",
    "           color=\"grades\",\n",
    "           )#, animation_frame=\"seq_ids\", range_x=[-10,25], range_y=[-10,25])\n",
    "fig.update_traces(customdata=customdata,\n",
    "           hovertemplate=hovertemplate)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the evolution of the sequences through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.scatter(df,\n",
    "           x=\"x\",\n",
    "           y=\"y\",\n",
    "           color=\"grades\",\n",
    "           hover_data=\"seq_ids\",\n",
    "           animation_frame=\"pic_ids\",\n",
    "           range_color=[2,7], range_x=[-10,25], range_y=[-10,25])\n",
    "fig.layout.updatemenus[0].buttons[0].args[1][\"transition\"][\"duration\"] = 0\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the whole sequences one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.scatter(df,\n",
    "           x=\"x\",\n",
    "           y=\"y\",\n",
    "           color=\"grades\",\n",
    "           hover_data=\"pic_ids\",\n",
    "           animation_frame=\"seq_ids\",\n",
    "           range_x=[-10,25],\n",
    "           range_y=[-10,25],\n",
    "           range_color=[2,7])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "seq = 72\n",
    "seq2= 77\n",
    "seq_ids = np.array(test_seq_ids if show_test else train_seq_ids)\n",
    "features = test_features[(seq_ids==seq)] if show_test else train_features[(seq_ids==seq)]\n",
    "features2= test_features[(seq_ids==seq2)] if show_test else train_features[(seq_ids==seq2)]\n",
    "\n",
    "print(features.shape)\n",
    "print(features2.shape)\n",
    "concat = torch.cat((features, features2))\n",
    "dist = pairwise_distances(concat, metric=\"cosine\", n_jobs=-1)\n",
    "norms = np.diag(np.log(norm(concat, axis=1)))\n",
    "norms = pairwise_distances(np.expand_dims(np.log(norm(concat, axis=1)), 1), metric=\"euclidean\", n_jobs=-1)\n",
    "# TODO something to do with the norms of the feature vectors?x/\n",
    "px.imshow(dist).show()\n",
    "px.imshow(norms).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for grade 2 vs all: 0.713\n",
      "Accuracy for grade 3 vs all: 0.573\n",
      "Accuracy for grade 4 vs all: 0.549\n",
      "Accuracy for grade 5 vs all: 0.802\n",
      "Accuracy for grade 6 vs all: 0.897\n",
      "Accuracy for grade 7 vs all: 0.500\n",
      "Accuracy for all: 0.464\n",
      "Confusion Matrix\n",
      "[[4704 1843  447  470  306    0]\n",
      " [1705 2086  869 1016  213    0]\n",
      " [ 436 1009  963 1622  172    0]\n",
      " [ 283  525  937 5637   26    0]\n",
      " [ 282  161   68   29 2671    0]\n",
      " [   4    4    2    8    0    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from lib.utils.evaluation import print_confusion_matrix\n",
    "\n",
    "for grade in range(2,8):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=11,)\n",
    "    neigh.fit(X=train_features, y=train_grades==grade)\n",
    "    predictions = neigh.predict(test_features)\n",
    "    acc = balanced_accuracy_score(test_grades==grade, predictions)\n",
    "    print(f\"Accuracy for grade {grade} vs all: {acc:.3f}\")\n",
    "    #print_confusion_matrix(predictions, test_grades==grade)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=11,)\n",
    "neigh.fit(X=train_features, y=train_grades)\n",
    "predictions = neigh.predict(test_features)\n",
    "acc = balanced_accuracy_score(test_grades, predictions)\n",
    "print(f\"Accuracy for all: {acc:.3f}\")\n",
    "print_confusion_matrix(predictions, test_grades)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO FORECASTING USING NN CLASSIFICATION/REGRESSION\n",
    "\n",
    "- NN to find the closest known examples\n",
    "- From these known examples we see what the passed forecast has been, we follow the typhoon's trajectory in the latent space\n",
    "\n",
    "### TODO Extra-Tropical storm prediction using latent space boundaries\n",
    "- Try to find the transition\n",
    "- SVM?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "typhoon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
